# -*- coding: utf-8 -*-
"""LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1No_9DalqI1Q-m4NtjscbdrAuHjzH5zdY

# 런타임 GPU확인
"""

import os, math, random, platform, glob
import numpy as np
import pandas as pd
import torch, torch.nn as nn
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from sklearn.preprocessing import RobustScaler
from tqdm import tqdm

# -------------------------
# Seed & device
# -------------------------
SEED = 42
random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
if DEVICE.type=="cuda":
    torch.cuda.manual_seed(SEED)
    torch.backends.cudnn.deterministic=True
    torch.backends.cudnn.benchmark=False

print("Python:", platform.python_version())
print("Torch  :", torch.__version__)
print("CUDA   :", torch.version.cuda)
print("Device :", DEVICE)

BASE_DIR   = "."   # 노트북 기준
TRAIN_PATH = f"{BASE_DIR}/train/train.csv"
TEST_DIR   = f"{BASE_DIR}/test"
SAMPLE_SUB = f"{BASE_DIR}/sample_submission.csv"
OUT_PATH   = f"{BASE_DIR}/submission.csv"

LOOKBACK, PREDICT = 28, 7
EPOCHS    = 16
BATCH     = 512
LR_MAX    = 2e-3
HIDDEN    = 160
LAYERS    = 2
DROPOUT   = 0.25
SCALE_MODE = "log1p"   # "log1p"(권장) or "robust"
USE_RECENCY_WEIGHTS = True
NEGATIVE_STRATEGY_TRAIN = "zero"   # train 전용: "zero"|"abs"|"drop"|"neighbor_avg"|"none"
# test 입력은 규칙상 주어진 28일을 그대로 쓰므로 음수처리 X (스케일만 적용)

"""# 3. 유틸/전처리(파생변수 + 음수 처리 4안)

"""

def split_shop_menu(name):
    if isinstance(name, str) and "_" in name:
        a,b = name.split("_", 1); return a,b
    return name,""

def categorize_menu(menu_name: str) -> str:
    if not isinstance(menu_name, str): return "기타"
    s = menu_name.lower()
    summer = ["빙수","shaved","아이스","냉","콜드","여름","수박","망고"]
    winter = ["따뜻","hot","온","겨울","호빵","어묵","오뎅","호떡","붕어빵"]
    alcohol = ["맥주","soju","소주","와인","wine","막걸리","사케","위스키","칵테일","highball","하이볼","소맥","주류","beer","sake"]
    nonalc = ["주스","에이드","스무디","라떼","커피","차","tea","티","아메리카노","콜라","사이다","스프라이트","음료","우유"]
    venue  = ["대관","장소","홀대여","룸대여","room","space","연회장","banquet","대여","컨벤션","hall","convention"]
    group  = ["단체","뷔페","코스","패키지","세트","연회","행사"]
    side   = ["사이드","안주","튀김","감자","김치","디저트","케이크","빵","쿠키","과자","토핑"]
    main   = ["정식","세트","메인","bbq","회","스테이크","파스타","라면","국수","비빔밥","한정식","덮밥","초밥","피자","컵밥","돈가스","짜장","짬뽕","불고기","갈비","탕","찌개","국","면","밥","버거","샐러드"]
    if any(k in s for k in summer): return "계절_여름"
    if any(k in s for k in winter): return "계절_겨울"
    if any(k in s for k in venue):  return "장소대여"
    if any(k in s for k in alcohol):return "음료_술"
    if any(k in s for k in nonalc): return "음료_무알코올"
    if any(k in s for k in group):  return "음식_단체"
    if any(k in s for k in side):   return "음식_사이드"
    if any(k in s for k in main):   return "음식_메인"
    return "기타"

def add_features(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["영업일자"] = pd.to_datetime(df["영업일자"], errors="coerce")
    df["요일"] = df["영업일자"].dt.weekday.astype(int).clip(0,6)
    df["개월"] = (df["영업일자"].dt.month-1).astype(int).clip(0,11)
    shops, menus = zip(*df["영업장명_메뉴명"].map(split_shop_menu))
    df["업장"] = list(shops)
    df["메뉴명"] = list(menus)
    df["메뉴유형"] = df["메뉴명"].map(categorize_menu)
    return df

def handle_negatives_train(df: pd.DataFrame, strategy: str) -> pd.DataFrame:
    df = df.copy()
    if strategy == "zero":
        df.loc[df["매출수량"]<0,"매출수량"]=0
    elif strategy == "drop":
        df = df[df["매출수량"]>=0].reset_index(drop=True)
    elif strategy == "abs":
        df["매출수량"]=df["매출수량"].abs()
    elif strategy == "neighbor_avg":
        def repair(g):
            s = g["매출수량"].astype(float); mask = s<0
            anchor = s.mask(mask); prev, nxt = anchor.ffill(), anchor.bfill()
            rep = s.copy(); rep[mask] = ((prev+nxt)/2.0)[mask]
            g = g.copy(); g["매출수량"] = rep.fillna(prev).fillna(nxt).fillna(0.0)
            return g
        df = df.groupby("영업장명_메뉴명", group_keys=False).apply(repair).reset_index(drop=True)
    # "none"이면 그대로
    return df

class IDEncoder:
    def __init__(self, use_unk=True):
        self.map = {"<UNK>":0} if use_unk else {}
        self.use_unk=use_unk
    def fit(self, arr):
        for v in arr:
            if v not in self.map: self.map[v]=len(self.map)
        return self
    def transform(self, arr):
        return np.array([self.map.get(v,0) for v in arr], dtype=np.int64)
    @property
    def size(self): return len(self.map)
    def unk_index(self): return 0

def smape_np(y, p, eps=1e-8):
    y = np.asarray(y, float); p = np.asarray(p, float)
    mask = (np.abs(y)>0) & ((np.abs(y)+np.abs(p))>0)
    if mask.sum()==0: return np.nan
    return float(np.mean(2.0*np.abs(p[mask]-y[mask])/(np.abs(y[mask])+np.abs(p[mask])+eps)))

def smape_torch(y_true, y_pred, eps=1e-6):
    # y_true, y_pred: [B, 7]
    denom = y_true.abs() + y_pred.abs() + eps
    mask  = (y_true.abs() > 0).float()
    term  = 2.0 * (y_pred - y_true).abs() / denom
    per_sample = (term * mask).sum(dim=1) / mask.sum(dim=1).clamp_min(1.0)
    return per_sample  # [B]

# ----- Scalers -----
class Log1pScaler:
    def fit(self, x): return self
    def transform(self, x): return np.log1p(np.clip(np.asarray(x, float), 0, None))
    def inverse_transform(self, x): return np.expm1(np.asarray(x, float))

def make_scaler(tr_df, mode="log1p"):
    if mode=="robust":
        sc = RobustScaler().fit(tr_df[["매출수량"]])
        class _Wrap:
            def __init__(self, sc): self.sc=sc
            def fit(self, x): return self
            def transform(self, x):
                return self.sc.transform(np.asarray(x, float).reshape(-1,1)).reshape(-1)
            def inverse_transform(self, x):
                return self.sc.inverse_transform(np.asarray(x, float).reshape(-1,1)).reshape(-1)
        return _Wrap(sc)
    else:
        return Log1pScaler()

"""# Dataset & Model 정의"""

class SalesDatasetTrain(Dataset):
    """
    train.csv 에서 (28 → 7) 슬라이딩 윈도우 전부 생성.
    - 값: 지정 스케일로 변환
    - 캘린더(과거28/미래7), 업장/메뉴유형 임베딩 id
    - 간단한 윈도우 통계(last, mean7, mean28) 추가
    """
    def __init__(self, df, scaler, shop_enc, type_enc, lookback=28, predict=7, recency_gamma=0.997):
        self.samples=[]; self.weights=[]
        df = df.sort_values(["영업장명_메뉴명","영업일자"]).copy()
        for (series, shop, mtype), g in df.groupby(["영업장명_메뉴명","업장","메뉴유형"]):
            g = g.sort_values("영업일자").reset_index(drop=True)
            n = len(g) - (lookback+predict) + 1
            if n<=0: continue
            vals = scaler.transform(g["매출수량"].values)
            wd   = g["요일"].values.astype(int)         # 0~6
            mo   = g["개월"].values.astype(int)         # 0~11
            sid  = shop_enc.map.get(shop, shop_enc.unk_index())
            tid  = type_enc.map.get(mtype, type_enc.unk_index())
            for i in range(n):
                past = slice(i, i+lookback)
                fut  = slice(i+lookback, i+lookback+predict)
                x  = vals[past].astype(np.float32)
                y  = vals[fut].astype(np.float32)
                w_p= wd[past]; m_p= mo[past]
                w_f= wd[fut];  m_f= mo[fut]
                last = x[-1]; mean7 = x[-7:].mean(); mean28 = x.mean()
                stats = np.array([last, mean7, mean28], np.float32)
                self.samples.append((
                    torch.tensor(x).unsqueeze(-1),                # [28,1]
                    torch.tensor(w_p, dtype=torch.long),          # [28]
                    torch.tensor(m_p, dtype=torch.long),          # [28]
                    torch.tensor(w_f, dtype=torch.long),          # [7]
                    torch.tensor(m_f, dtype=torch.long),          # [7]
                    torch.tensor(int(sid), dtype=torch.long),
                    torch.tensor(int(tid), dtype=torch.long),
                    torch.tensor(stats),                          # [3]
                    torch.tensor(y)                               # [7]
                ))
                age = (n-1) - i
                self.weights.append(recency_gamma**age)
        self.weights = np.array(self.weights, np.float32)

    def __len__(self): return len(self.samples)
    def __getitem__(self, idx): return self.samples[idx]

"""# 5 학습/평가 루프 + 전략별 실행 함수

"""

class LSTMCalHead(nn.Module):
    def __init__(self, hidden=128, layers=2, n_shops=1, n_types=1, dropout=0.3, stats_dim=3):
        super().__init__()
        self.emb_w   = nn.Embedding(7, 4)
        self.emb_m   = nn.Embedding(12,3)
        self.emb_shop= nn.Embedding(max(1,n_shops), 16)
        self.emb_type= nn.Embedding(max(1,n_types), 8)
        self.lstm = nn.LSTM(1+4+3, hidden, layers, batch_first=True, bidirectional=True)
        self.drop = nn.Dropout(dropout)
        in_dim = hidden*2 + 16 + 8 + 4 + 3 + stats_dim  # enc + shop + type + fut_w + fut_m + stats
        self.head = nn.Sequential(
            nn.Linear(in_dim, 192),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(192, 1)
        )

    def forward(self, x_val, w_p, m_p, w_f, m_f, sid, tid, stats):
        ew = self.emb_w(w_p); em = self.emb_m(m_p)
        x  = torch.cat([x_val, ew, em], dim=2)   # [B,28,1+4+3]
        enc,_ = self.lstm(x)                     # [B,28,2H]
        enc = enc[:, -1, :]                      # [B,2H]
        es, et = self.emb_shop(sid), self.emb_type(tid)
        outs=[]
        for t in range(w_f.shape[1]):            # 7 steps
            ewf = self.emb_w(w_f[:,t])           # [B,4]
            emf = self.emb_m(m_f[:,t])           # [B,3]
            h = torch.cat([enc, es, et, ewf, emf, stats], dim=1)
            y = self.head(self.drop(h))          # [B,1]
            outs.append(y)
        return torch.cat(outs, dim=1)            # [B,7]

# -------------------------
# Train
# -------------------------
def train_and_build(tr_path):
    # 1) load & preprocess(train only)
    tr = pd.read_csv(tr_path)
    tr = add_features(handle_negatives_train(tr, NEGATIVE_STRATEGY_TRAIN))

    # 2) encoders (fit on train only)
    shop_enc = IDEncoder().fit(tr["업장"].tolist())
    type_enc = IDEncoder().fit(tr["메뉴유형"].tolist())

    # 3) scaler (fit on train only)
    scaler = make_scaler(tr, mode=SCALE_MODE)

    # 4) dataset/loader
    train_ds = SalesDatasetTrain(tr, scaler, shop_enc, type_enc, LOOKBACK, PREDICT, recency_gamma=0.997)
    if len(train_ds)==0:
        raise RuntimeError("No training samples.")

    if USE_RECENCY_WEIGHTS:
        weights = train_ds.weights / (train_ds.weights.mean() + 1e-8)
        sampler = WeightedRandomSampler(weights, num_samples=len(train_ds), replacement=True)
        train_loader = DataLoader(train_ds, batch_size=BATCH, sampler=sampler,
                                  num_workers=2, pin_memory=(DEVICE.type=="cuda"))
    else:
        train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True,
                                  num_workers=2, pin_memory=(DEVICE.type=="cuda"))

    # 5) model/optim
    model = LSTMCalHead(HIDDEN, LAYERS, shop_enc.size, type_enc.size, DROPOUT).to(DEVICE)
    opt = torch.optim.AdamW(model.parameters(), lr=LR_MAX, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.OneCycleLR(
        opt, max_lr=LR_MAX, steps_per_epoch=len(train_loader), epochs=EPOCHS,
        pct_start=0.30, div_factor=10.0, final_div_factor=1e3, anneal_strategy="cos"
    )
    l1 = nn.L1Loss()

    # 6) loop
    for ep in range(1, EPOCHS+1):
        model.train(); run=0.0
        pbar = tqdm(train_loader, desc=f"[train] epoch {ep}/{EPOCHS}", leave=False)
        for step, batch in enumerate(pbar, start=1):
            x, w_p, m_p, w_f, m_f, sid, tid, stats, y = [t.to(DEVICE) for t in batch]
            opt.zero_grad(set_to_none=True)
            pred = model(x, w_p, m_p, w_f, m_f, sid, tid, stats)          # scaled
            if SCALE_MODE == "log1p":
                pred_orig = torch.expm1(pred); y_orig = torch.expm1(y)
            else:
                # robust는 학습시 원복 필요 없지만, SMAPE 계산하려면 원단위가 필요
                pred_np = pred.detach().cpu().numpy()
                y_np    = y.detach().cpu().numpy()
                pred_orig = torch.tensor(scaler.inverse_transform(pred_np), dtype=torch.float32, device=DEVICE)
                y_orig    = torch.tensor(scaler.inverse_transform(y_np), dtype=torch.float32, device=DEVICE)
            smape_loss = smape_torch(y_orig, pred_orig).mean()
            l1_loss    = l1(pred, y)
            loss = 0.6 * l1_loss + 0.4 * smape_loss

            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            opt.step(); scheduler.step()
            run += float(loss.item())
            pbar.set_postfix(loss=f"{run/step:.4f}")

    return model, scaler, shop_enc, type_enc

"""# 전략별 학습/평가

"""

def make_future_calendar(last_date, horizon=7):
    days = pd.date_range(last_date + pd.Timedelta(days=1), periods=horizon, freq="D")
    w = days.weekday.values.astype(int)           # 0~6
    m = (days.month.values.astype(int) - 1)       # 0~11
    return w, m

@torch.no_grad()
def predict_group(model, scaler, shop_enc, type_enc, g):
    # g: TEST_xx 내 특정 "영업장명_메뉴명"의 28행 데이터프레임
    g = g.sort_values("영업일자").copy()
    assert len(g) >= LOOKBACK
    # past 28
    g_look = g.tail(LOOKBACK).copy()
    # past calendar from data
    w_p = g_look["요일"].values.astype(int)
    m_p = (g_look["개월"].values.astype(int))

    # future calendar (+1~+7)
    last_date = g_look["영업일자"].max()
    w_f, m_f = make_future_calendar(last_date, PREDICT)

    # values → scaled
    x_vals = g_look["매출수량"].values.astype(float)
    x_scaled = scaler.transform(x_vals).astype(np.float32)

    # ids
    shop, menu = split_shop_menu(g_look["영업장명_메뉴명"].iloc[0])
    sid = shop_enc.map.get(shop, shop_enc.unk_index())
    mtype = categorize_menu(menu)
    tid = type_enc.map.get(mtype, type_enc.unk_index())

    # stats on scaled
    last = x_scaled[-1]; mean7 = x_scaled[-7:].mean(); mean28 = x_scaled.mean()
    stats = np.array([last, mean7, mean28], np.float32)

    # tensors
    x_t   = torch.tensor(x_scaled).unsqueeze(0).unsqueeze(-1).to(DEVICE) # [1,28,1]
    w_p_t = torch.tensor(w_p, dtype=torch.long).unsqueeze(0).to(DEVICE)  # [1,28]
    m_p_t = torch.tensor(m_p, dtype=torch.long).unsqueeze(0).to(DEVICE)  # [1,28]
    w_f_t = torch.tensor(w_f, dtype=torch.long).unsqueeze(0).to(DEVICE)  # [1,7]
    m_f_t = torch.tensor(m_f, dtype=torch.long).unsqueeze(0).to(DEVICE)  # [1,7]
    sid_t = torch.tensor([sid], dtype=torch.long).to(DEVICE)
    tid_t = torch.tensor([tid], dtype=torch.long).to(DEVICE)
    st_t  = torch.tensor(stats).unsqueeze(0).to(DEVICE)

    model.eval()
    pred_scaled = model(x_t, w_p_t, m_p_t, w_f_t, m_f_t, sid_t, tid_t, st_t).cpu().numpy().reshape(-1)

    # inverse & clip (원 단위)
    if SCALE_MODE == "log1p":
        pred = np.expm1(pred_scaled)
    else:
        pred = RobustScaler().inverse_transform  # (사용하지 않음: robust면 별도 wrapper 필요)
        raise NotImplementedError("robust 모드 추론 inverse는 wrapper 사용해 구현하세요.")
    pred = np.clip(pred, 0, None)
    return pred

def main():
    # Train
    model, scaler, shop_enc, type_enc = train_and_build(TRAIN_PATH)

    # Load sample for column order
    sample = pd.read_csv(SAMPLE_SUB)
    all_rows = []

    # Iterate TEST_XX
    test_files = sorted(glob.glob(f"{TEST_DIR}/TEST_*.csv"))
    for tp in test_files:
        test_id = os.path.basename(tp).split(".")[0]
        df = pd.read_csv(tp)
        # 안전 전처리(캘린더만 추가) — 음수 보정 X
        df["영업일자"] = pd.to_datetime(df["영업일자"], errors="coerce")
        df["요일"] = df["영업일자"].dt.weekday.astype(int).clip(0,6)
        df["개월"] = (df["영업일자"].dt.month-1).astype(int).clip(0,11)

        # 그룹별 28행 예측
        for key, g in df.groupby("영업장명_메뉴명"):
            if len(g) < LOOKBACK:
                # 규칙상 28일 입력만 사용 → 28 미만이면 스킵(대회 데이터는 보통 28 보장)
                continue
            pred7 = predict_group(model, scaler, shop_enc, type_enc, g)
            for d, v in enumerate(pred7, start=1):
                all_rows.append({
                    "영업일자": f"{test_id}+{d}일",
                    "영업장명_메뉴명": key,
                    "매출수량": float(v)
                })

    # Long → Wide
    pred_long = pd.DataFrame(all_rows)
    pred_wide = pred_long.pivot(index="영업일자",
                                columns="영업장명_메뉴명",
                                values="매출수량").reset_index()

    # align to sample_submission
    for col in sample.columns:
        if col not in pred_wide.columns:
            pred_wide[col] = 0
    pred_wide = pred_wide[sample.columns]

    pred_wide.to_csv(OUT_PATH, index=False, encoding="utf-8-sig")
    print("Saved:", OUT_PATH)

if __name__ == "__main__":
    main()