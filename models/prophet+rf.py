# -*- coding: utf-8 -*-
"""prophet+rf.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PXOV8xuwPA7W_4ry8nO3fB3KwIP-_00G

## 데이터 전처리 및 특징 변수 생성
"""

import pandas as pd
import numpy as np
from prophet import Prophet
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import RandomizedSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.metrics import make_scorer
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from google.colab import drive
drive.mount('/content/drive')

import matplotlib.font_manager as fm
font_path = '/content/drive/MyDrive/SeoulNamsanC.otf'
font_prop = fm.FontProperties(fname=font_path)

import matplotlib
matplotlib.rcParams['font.family'] = 'sans-serif'  # 또는 'Malgun Gothic', 'AppleGothic' 등 시스템에 있는 한글 폰트
plt.style.use('dark_background') # matplotlib 다크모드 설정

# 2.1. 데이터 로딩 및 초기 정제
# 훈련 데이터와 테스트 데이터 파일을 불러옵니다.
train_df_raw = pd.read_csv('/content/drive/MyDrive/lgaimers/train_split.csv')
# train_split.csv : 영업장명_메뉴명 -> 영업장명, 메뉴명 칼럼 각각 분리 (요일 칼럼 X)
test_df_raw = pd.read_csv('/content/drive/MyDrive/lgaimers/TEST_00.csv')
print("훈련 데이터 초기 5행:")
print(train_df_raw.head())
print("\n테스트 데이터 초기 5행:")
print(test_df_raw.head())

# 예측 대상 영업장 및 메뉴를 필터링합니다.
# 훈련 데이터에서 '느티나무 셀프BBQ'의 데이터만 추출합니다.
train_bbq_df = train_df_raw[train_df_raw['영업장명'] == '느티나무 셀프BBQ']

# 예측 대상 메뉴와 후처리에 사용될 메뉴 목록을 정의합니다.
target_menu = '1인 수저세트'
auxiliary_menus = ['BBQ55(단체)', '대여료 30,000원']
all_relevant_menus = [target_menu] + auxiliary_menus

# 예측 대상 및 보조 메뉴 데이터프레임 생성
target_df_train = train_bbq_df[train_bbq_df['메뉴명'] == target_menu]
aux_df_train_bbq55 = train_bbq_df[train_bbq_df['메뉴명'] == 'BBQ55(단체)']
aux_df_train_rental30k = train_bbq_df[train_bbq_df['메뉴명'] == '대여료 30,000원']

# 2.2. Prophet 모델을 위한 데이터 변환
# Prophet 모델은 'ds'와 'y' 열을 사용하므로, 열 이름을 변경하고 날짜 형식을 변환합니다.
def prepare_prophet_data(df, date_col, value_col):
    df_prophet = df[[date_col, value_col]].copy()
    df_prophet.columns = ['ds', 'y']
    df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])
    return df_prophet

prophet_data_target = prepare_prophet_data(target_df_train, '영업일자', '매출수량')
prophet_data_bbq55 = prepare_prophet_data(aux_df_train_bbq55, '영업일자', '매출수량')
prophet_data_rental30k = prepare_prophet_data(aux_df_train_rental30k, '영업일자', '매출수량')

print("\nProphet 모델용 훈련 데이터(1인 수저세트) 5행:")
print(prophet_data_target.head())

# 2.3. Random Forest 모델을 위한 특징 변수 생성
# Random Forest 모델의 특징 변수는 요일과 전날 매출량으로 제한합니다.
# 이는 모델의 역할을 명확히 구분하고, 메뉴 간의 상호작용을 후처리 단계에서 다루기 위함입니다.
def create_rf_features(df):
    df['영업일자'] = pd.to_datetime(df['영업일자'])
    df['요일'] = df['영업일자'].dt.day_name()
    df['lag_1'] = df['매출수량'].shift(1).fillna(method='bfill') # 전날 매출량, 시프트로 인해 빈 칸은 아랫값으로 채움
    return df

target_df_train = create_rf_features(target_df_train.copy())
aux_df_train_bbq55 = create_rf_features(aux_df_train_bbq55.copy())
aux_df_train_rental30k = create_rf_features(aux_df_train_rental30k.copy())

# 원-핫 인코딩을 위한 인코더 초기화 및 학습
ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
ohe.fit(target_df_train[['요일']])

# 랜덤포레스트에 입력되는 특징변수를 반환 - 요일, 전날매출수량, 현매출수량 변수 포함 예정
def transform_rf_features(df):
    # 요일 칼럼을 원-핫 인코딩
    df_encoded = pd.DataFrame(ohe.transform(df[['요일']]), columns=ohe.get_feature_names_out(['요일']))
    X = pd.concat([df_encoded.reset_index(drop=True), df['lag_1'].reset_index(drop=True), df['매출수량'].reset_index(drop=True)], axis=1)
    return X

def transform_rf_features_test(df):
    # 요일 칼럼을 원-핫 인코딩
    df_encoded = pd.DataFrame(ohe.transform(df[['요일']]), columns=ohe.get_feature_names_out(['요일']))
    X = pd.concat([df_encoded.reset_index(drop=True), df['lag_1'].reset_index(drop=True)], axis=1)
    return X

X_train_target = transform_rf_features(target_df_train)
y_train_target = target_df_train['매출수량']

print("\nRandom Forest 특징 변수(X_train_target) 5행:")
print(X_train_target.head())
print(X_train_target.shape)
print("\nRandom Forest 타겟 변수(y_train_target) 5행:")
print(y_train_target.head())
print(y_train_target.shape)

"""## Prophet 모델 학습 및 예측"""

# 3.1. Prophet 모델 학습 및 예측
m_prophet_target = Prophet(daily_seasonality=False, weekly_seasonality=True, yearly_seasonality=True)
m_prophet_target.fit(prophet_data_target)

# Prophet의 훈련 데이터 예측값 생성
# 훈련데이터와 모델입력(예측목적)으로 들어가는 데이터가 같음. 'in-sample prediction'
prophet_forecast_train = m_prophet_target.predict(prophet_data_target)

# 3.2. Prophet 모델 잔차 계산
# Prophet의 예측값과 실제값의 차이를 계산하여 Random Forest의 학습 데이터로 사용합니다.
y_train_prophet = prophet_forecast_train['yhat']
residuals_train = y_train_target - y_train_prophet.values

# 3.3. Random Forest 모델 학습 및 잔차 예측
# Random Forest 모델을 학습시켜 Prophet의 잔차를 예측합니다.
rf_model_target = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model_target.fit(X_train_target, residuals_train)

# 3.4. 하이브리드 모델(Prophet + RF) 기본 예측값 산출 (훈련 데이터에 대한)
# Prophet 예측값에 RF 잔차 예측값을 더하여 하이브리드 모델의 기본 예측값을 생성합니다.
residuals_predicted_train = rf_model_target.predict(X_train_target)
y_hat_base_train = y_train_prophet + residuals_predicted_train

print("\nProphet 훈련 데이터 예측값 5행:")
print(prophet_forecast_train[['ds', 'yhat']].head())
print(prophet_forecast_train[['ds', 'yhat']].shape)

print("\nProphet 잔차(y_train_target - y_train_prophet) 5행:")
print(residuals_train.head())
print(residuals_train.shape)

print("\nRandom Forest 훈련 데이터 잔차 예측값 5행:")
print(residuals_predicted_train[:5])
print(residuals_predicted_train[:5].shape)

print("\n하이브리드 모델 기본 예측값(훈련 데이터) 5행:")
print(y_hat_base_train.head())
print(y_hat_base_train.shape)

"""## 후처리 로직에 필요한 보조 메뉴들의 Prophet+RF 모델을 구축하고 예측
1인수저세트 메뉴와 상관계수가 높은 타메뉴 간 어느 정도 비례관계를 유지하기 위해 타메뉴 또한 테스트 기간에 대한 예측값을 얻어야 함.
"""

# # 4.1. 후처리 로직 구현을 위한 예측값 준비 및 평균 판매량 계산
# # 후처리 로직에 필요한 보조 메뉴들의 Prophet+RF 모델을 구축하고 예측합니다.
# def train_and_predict_hybrid(train_df, future_dates):
#     print("train_df shape:", train_df.shape)
#     print("future_dates type:", type(future_dates))

#     # Prophet 데이터 준비
#     prophet_data = prepare_prophet_data(train_df, '영업일자', '매출수량')
#     m_prophet = Prophet(daily_seasonality=False, weekly_seasonality=True, yearly_seasonality=True)
#     m_prophet.fit(prophet_data)

#     # Random Forest 데이터 준비
#     train_df = create_rf_features(train_df.copy())
#     X_train = transform_rf_features(train_df)
#     y_train = train_df['매출수량']

#     # 잔차 계산 및 RF 학습
#     prophet_forecast_train = m_prophet.predict(prophet_data)
#     residuals_train = y_train - prophet_forecast_train['yhat'].values
#     rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
#     rf_model.fit(X_train, residuals_train)

#     # 미래 예측
#     future = pd.DataFrame({'ds': future_dates})
#     future_prophet = m_prophet.predict(future)

#     # RF 잔차 예측을 위한 특징 변수 준비
#     test_features_df = future.copy()
#     test_features_df['요일'] = test_features_df['ds'].dt.day_name()

#     # 과거 데이터와 테스트 데이터 결합 후 lag_1 변수 생성
#     combined_df = pd.concat([train_df[['영업일자', '매출수량']], test_features_df[['ds']]], axis=0)
#     combined_df.rename(columns={'영업일자': 'ds'}, inplace=True)
#     combined_df.set_index('ds', inplace=True)

#     # 주의: 테스트 기간의 매출수량은 알 수 없으므로, 예측값을 활용하여 lag_1을 생성해야 함
#     # 여기서는 단순화를 위해 train 데이터의 마지막 값으로 채움
#     test_features_df['lag_1'] = combined_df['매출수량'].shift(1).fillna(method='bfill').loc[future_dates].to_numpy().reshape(-1)

#     X_test = transform_rf_features(test_features_df)
#     residuals_predicted_test = rf_model.predict(X_test)

#     # 최종 예측값
#     y_hat_base = future_prophet['yhat'].values + residuals_predicted_test

#     return y_hat_base, train_df['매출수량'].mean()

def smape(y_true, y_pred):
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0
    diff = np.abs(y_true - y_pred) / denominator
    diff[denominator == 0] = 0.0  # 0/0 방지
    return np.mean(diff)

smape_scorer = make_scorer(smape, greater_is_better=False)

def params_search(X_train1, residuals_train1):
    # 랜덤포레스트 하이퍼파라미터 후보 정의
    param_dist = {
        'n_estimators': [50, 100, 200, 300],
        'max_depth': [None, 5, 10, 20, 30],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['auto', 'sqrt', 'log2', 0.5, 0.7]
    }

    rf = RandomForestRegressor(random_state=42)

    # RandomizedSearchCV 객체 생성
    random_search = RandomizedSearchCV(
        estimator=rf,
        param_distributions=param_dist,
        n_iter=50,                # 탐색 횟수 (적절히 조절)
        cv=3,                     # 교차검증 폴드 수
        scoring=smape_scorer,
        n_jobs=-1,                # 모든 CPU 사용
        verbose=2,
        random_state=42
    )

    # 하이퍼파라미터 탐색 수행
    random_search.fit(X_train1, residuals_train1)

    # 최적 모델 추출
    best_rf_model = random_search.best_estimator_
    return best_rf_model

def train_and_predict_hybrid(train_df, future_dates):

    prophet_data = prepare_prophet_data(train_df, '영업일자', '매출수량')

    m_prophet = Prophet(daily_seasonality=False, weekly_seasonality=True, yearly_seasonality=True)
    m_prophet.fit(prophet_data)

    train_df = create_rf_features(train_df.copy())
    X_train = transform_rf_features(train_df)
    y_train = train_df['매출수량']
    prophet_forecast_train = m_prophet.predict(prophet_data)
    residuals_train = y_train - prophet_forecast_train['yhat'].values

    # rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_model = params_search(X_train, residuals_train)
    rf_model.fit(X_train, residuals_train)

    future = pd.DataFrame({'ds': future_dates})
    future_prophet = m_prophet.predict(future)

    test_features_df = future.copy()
    test_features_df['요일'] = test_features_df['ds'].dt.day_name()

    # 훈련데이터의 마지막 전날매출수량을 테스트데이터의 첫 전날매출수량으로 사용하기 위해 우선 합침
    combined_df = train_df
    combined_df.rename(columns={'영업일자': 'ds'}, inplace=True)
    combined_df = pd.concat([train_df[['ds', '매출수량']], test_features_df[['ds']]], axis=0)
    combined_df.set_index('ds', inplace=True)

    lag_1_arr = combined_df['매출수량'].shift(1).fillna(method='bfill').loc[future_dates].to_numpy()
    test_features_df['lag_1'] = lag_1_arr.reshape(-1)

    ###
    X_test = transform_rf_features_test(test_features_df)
    residuals_predicted_test = rf_model.predict(X_test)
    y_hat_base = future_prophet['yhat'].values + residuals_predicted_test
    avg_sales = train_df['매출수량'].mean()

    return y_hat_base, avg_sales

# 테스트 데이터 기간 정의
test_dates = pd.to_datetime(test_df_raw['영업일자'].unique())

# 보조 메뉴 예측값 및 평균 판매량 계산
y_hat_bbq55, avg_bbq55 = train_and_predict_hybrid(aux_df_train_bbq55, test_dates)
y_hat_rental30k, avg_rental30k = train_and_predict_hybrid(aux_df_train_rental30k, test_dates)

# 4.2. 후처리 조정 계수 계산 로직 구현
# 보고서에서 제시된 상관계수를 사용합니다.
corr_bbq55 = 0.85
corr_rental30k = 0.72

# 조정 계수(adjustment_factor) 계산
adjustment_factor = ((y_hat_bbq55 / avg_bbq55) - 1) * corr_bbq55 + ((y_hat_rental30k / avg_rental30k) - 1) * corr_rental30k

print("\n후처리 조정 계수(adjustment_factor)의 일부:")
print(adjustment_factor[:5])

print()

"""## 테스트 데이터 로딩 및 최종 예측 실행"""

# 5.1. 테스트 데이터 로딩 및 최종 예측 실행
# 1인 수저세트의 Prophet 단독 모델 예측
future = pd.DataFrame({'ds': test_dates})
prophet_forecast_test_target = m_prophet_target.predict(future)

# 1인 수저세트의 Prophet + RF 하이브리드 모델 예측
test_features_df_target = future.copy()
test_features_df_target['요일'] = test_features_df_target['ds'].dt.day_name()
# 테스트 기간의 lag_1은 예측값이 아닌, 훈련 데이터의 마지막 값으로 채웁니다.
last_train_value = target_df_train['매출수량'].iloc[-1]
# test_features_df_target['lag_1'] = pd.concat(), pd.Series(prophet_forecast_test_target['yhat'].values[:-1])], ignore_index=True).values

# test_features_df_target lag_1 생성 부분
# Prophet 예측값
yhat = prophet_forecast_test_target['yhat'].values
# 훈련 데이터 마지막 매출수량
last_train_value = target_df_train['매출수량'].iloc[-1]
# lag_1 생성: [train 마지막 값, 예측값[:-1]]
lag_1 = np.concatenate([[last_train_value], yhat[:-1]])
# test_features_df_target에 lag_1 할당
test_features_df_target['lag_1'] = lag_1

X_test_target = transform_rf_features(test_features_df_target)
residuals_predicted_test_target = rf_model_target.predict(X_test_target)
y_hat_base_test = prophet_forecast_test_target['yhat'].values + residuals_predicted_test_target

# 후처리 로직을 적용한 최종 예측
y_hat_final_test = y_hat_base_test * (1 + adjustment_factor)
y_hat_final_test[y_hat_final_test < 0] = 0 # 예측값이 음수인 경우 0으로 처리

# 테스트 데이터 준비 (평가를 위해)
test_df = test_df_raw[test_df_raw['영업장명_메뉴명'] == '느티나무 셀프BBQ_1인 수저세트'].copy()
y_actual_test = test_df['매출수량'].values
test_dates_df = pd.DataFrame({'ds': pd.to_datetime(test_df['영업일자'])})

# 5.2. 모델 성능 평가 지표 계산
def calculate_metrics(y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    smape = np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred))) * 100
    return mae, rmse, smape

# Prophet 단독 모델 성능
y_hat_prophet_only_test = m_prophet_target.predict(test_dates_df)['yhat'].values
mae_prophet, rmse_prophet, smape_prophet = calculate_metrics(y_actual_test, y_hat_prophet_only_test)

# 하이브리드 모델(미조정) 성능
mae_base, rmse_base, smape_base = calculate_metrics(y_actual_test, y_hat_base_test)

# 최종 예측(후처리 반영) 성능
mae_final, rmse_final, smape_final = calculate_metrics(y_actual_test, y_hat_final_test)

# 5.3. 성능 지표 비교 분석
metrics_df = pd.DataFrame({
    'Model': ['model_prophet', 'model_base', 'model_final'],
    'MAE': [mae_prophet, mae_base, mae_final],
    'RMSE': [rmse_prophet, rmse_base, rmse_final],
    'SMAPE (%)': [smape_prophet, smape_base, smape_final]
})

print("\n\n모델별 예측 성능 지표 비교")
print(metrics_df)
print(smape_prophet, smape_base, smape_final)

"""## '1인 수저세트' 매출 예측 시계열 그래프"""

# 6.1. '1인 수저세트' 매출 예측 시계열 그래프
plt.figure(figsize=(15, 8))
plt.plot(test_dates, y_actual_test, label='Actual Sales', marker='o', color='white', linestyle='--')
plt.plot(test_dates, y_hat_prophet_only_test, label='Prophet Only Forecast', marker='x', color='red', linestyle=':')
plt.plot(test_dates, y_hat_base_test, label='Prophet + RF Forecast', marker='s', color='orange', linestyle='-.')
plt.plot(test_dates, y_hat_final_test, label='Final Forecast (Post-processed)', marker='^', color='green', linestyle='-')
plt.title('느티나무 셀프BBQ \'1인 수저세트\' 예측 결과 비교', fontsize=16, fontproperties=font_prop)
plt.xlabel('Date', fontsize=12)
plt.ylabel('Sales Quantity', fontsize=12)
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show();

# 6.2. 종합 결론
print("\n\n### 종합 결론 및 향후 개선 방안")
print("1. 모델 성능 요약:")
print(" - Prophet 모델은 장기적 추세와 계절성 패턴을 안정적으로 포착합니다.")
print(" - Random Forest는 Prophet의 잔차를 예측함으로써 단기적인 변동성을 보완하여 예측 정확도를 개선합니다.")
print(" - 특히, 다른 메뉴와의 상관관계를 반영한 후처리 로직은 예측 성능을 유의미하게 향상시킵니다. 이는 `BBQ55(단체)`와 같은 메뉴의 판매량이 증가할 때 `1인 수저세트`의 매출도 동반 상승하는 비즈니스 논리를 성공적으로 반영한 결과입니다.")
print("\n2. 향후 개선 방안:")
print(" - **외부 변수 추가**: 날씨, 휴일, 특별 이벤트 등 외부 요인을 모델에 추가하여 예측 정확도를 더욱 높일 수 있습니다.")
print(" - **동적 상관관계 분석**: 현재는 고정된 상관계수(0.85, 0.72)를 사용하지만, 메뉴 간의 상관관계를 주기적으로 재분석하거나 모델이 동적으로 학습하도록 개선할 수 있습니다.")
print(" - **모델 최적화**: 하이퍼파라미터 튜닝을 통해 Prophet과 Random Forest 모델의 성능을 추가로 최적화할 여지가 있습니다.")

# !rm -rf ~/.cache/matplotlib

# 1. 캐시 삭제
# !rm -rf ~/.cache/matplotlib

# 2. (런타임 재시작 후) 폰트 경로 지정 및 등록
# import matplotlib.pyplot as plt
# import matplotlib.font_manager as fm
# import numpy as np

# font_path = '/content/drive/MyDrive/SeoulNamsanC.otf'
# font_prop = fm.FontProperties(fname=font_path)

plt.style.use('dark_background')

# 3. 한글 포함 그래프
x = np.arange(0, 10, 0.1)
y = np.sin(x)
plt.figure(figsize=(8, 5))
plt.plot(x, y)
plt.title('사인 함수 그래프 (한글 테스트)',fontproperties=font_prop)
plt.xlabel('X 축',fontproperties=font_prop)
plt.ylabel('Y 축',fontproperties=font_prop)
plt.legend(['사인 함수'])
plt.grid(True)
plt.show();